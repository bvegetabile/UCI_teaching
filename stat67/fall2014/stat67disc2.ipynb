{
 "metadata": {
  "name": "",
  "signature": "sha256:8a1c499351aa1ab2c9ee3d91616bd19ec41a51c0986955f5debb23c24535f2a8"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# University of California - Irvine <br /> Statistics 67: Fall 2014 - Discussion 2\n",
      "# Visualizing & Displaying Data\n",
      "\n",
      "Author: Brian Vegetabile"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Overview\n",
      "\n",
      "In this notebook I give examples of how to summarize and visualize different types of data in both Python and R.  "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Dealing with Different Types of Data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Numerical Data\n",
      "\n",
      "In our first class we talked about the types of data.  Remember for numerical data we have the following qualities:\n",
      "\n",
      "   - Those variables where the adding, subtracting, averaging of their values makes sense.\n",
      "   - Types of Numerical:\n",
      "       - Continuous\n",
      "       - Discrete\n",
      "   - Examples of Numerical:\n",
      "       - Continuous - Resistance Measurements using an Ohmmeter\n",
      "       - Discrete - Counts of users online at specific times"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Dataset with Continuous Variables\n",
      "\n",
      "Old faithful Dataset\n",
      "\n",
      "Covariates:\n",
      "\n",
      "   - id:  Identifier of the eruption\n",
      "   - eruptions: Eruption time in mins\n",
      "   - waiting: Waiting time until next eruption\n",
      "   - link: http://www.stat.cmu.edu/~larry/all-of-statistics/=data/faithful.dat"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## How to Load Data\n",
      "\n",
      "A quick aside before we begin looking at any data, we need to get that data into our language of choice.  Below is how you can load data into either Python or R.  As always if you're stuck and things are broken... Ask Google."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Loading the data into Python"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "oldfaith = np.genfromtxt('oldfaithful.csv', delimiter=',', dtype=None, names=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "One way to load a csv into python is by the 'genfromtxt' function in the numpy library.  This gives you a numpy object which is convienent for plotting with matplotlib.  If the first row of the csv contains the names of the file, then you can use the \"names=True\" option to bring those in.  This allows indexing by names."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"First 5 eruption times: {}\".format(oldfaith['eruptions'][:5])\n",
      "print \"First 5 waiting times:  {}\".format(oldfaith['waiting'][:5])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Loading the data into R\n",
      "\n",
      "If you have R Studio installed and you're in the correct working directory with the data, the following commands will allow you to load the data into R.  We will assume you're in this working directory for the rest of this notebook.  The 'head' command (just like in Unix) allows you to see the first few rows of the data frame that was created.  The carat '>' represents commands you can enter at the R command line or put into an R script.\n",
      "\n",
      "    > oldfaith = read.csv('oldfaithful.csv')\n",
      "    > head(oldfaith)\n",
      "      id eruptions waiting\n",
      "    1  1     3.600      79\n",
      "    2  2     1.800      54\n",
      "    3  3     3.333      74\n",
      "    4  4     2.283      62\n",
      "    5  5     4.533      85\n",
      "    6  6     2.883      55\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Summarizing Numerical Data\n",
      "\n",
      "Before ever looking at any plots, there are some very natural things to look at when you're summarizing data. \n",
      "\n",
      "## Sample Mean\n",
      "\n",
      "The first summary that is always described in basic statistics is the mean of a sample. The sample mean of a numerical variable is computed at the sum of all of the observations divided by the number of observations. '\n",
      "\n",
      "\\begin{eqnarray*}\n",
      "    \\bar x = \\frac{x_1 + x_2 + \\dots + x_n}{n}\n",
      "\\end{eqnarray*}\n",
      "\n",
      "where $x_1, x_2, \\dots, x_n$ represent the observed values.\n",
      "\n",
      "### Sample Mean in Python\n",
      "\n",
      "Let's take a look at the mean eruption time of the dataset...."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "eruption_mean = np.mean(oldfaith['eruptions'])\n",
      "print \"\"\"Mean Eruption Time: {0:.3} mins\"\"\".format(eruption_mean)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Sample Mean in R\n",
      "\n",
      "    > mean(oldfaith$eruption)\n",
      "    [1] 3.487783\n",
      "    \n",
      "Note: In Python we are accessing the column of eruptions using the brackets oldfaith['eruptions'].  In R, read.csv() returns a dataframe object that allows you to accessing the named columns using the \\$ sign such as oldfaith\\$eruptions"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Sample Median\n",
      "\n",
      "The sample median is the observation that is the middle of the data.  If you sort the data from the lowest value to the highest value and there is an odd number of data points, the median is the number exactly in the middle.  If there is an odd number of data points, the median is the average of the two middle numbers.\n",
      "\n",
      "### Sample Median in Python"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "eruption_median = np.median(oldfaith['eruptions'])\n",
      "print \"\"\"Median Eruption Time: {0:.3} mins\"\"\".format(eruption_median)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Sample Median in R\n",
      "\n",
      "    > median(oldfaith$eruptions)\n",
      "    [1] 4"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Sample Minimum & Sample Maximum\n",
      "\n",
      "Observing the sample minimum and sample maximum allow you to get an idea of the range of values that you have in your dataset.  This provides insight into potential outliers from the get-go as well as gives an idea of the range of data for which inference will be applicable. \n",
      "\n",
      "### Sample Minimum and Maximum in Python\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "eruption_min = np.min(oldfaith['eruptions'])\n",
      "eruption_max = np.max(oldfaith['eruptions']) \n",
      "\n",
      "print \"\"\"Minimum Eruption Time: {0:.3}\n",
      "Maximum Eruption Time: {1:.3}\"\"\".format(eruption_min, eruption_max)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Sample Minimum and Maximum in R\n",
      "\n",
      "    > min(oldfaith$eruptions)\n",
      "    [1] 1.6\n",
      "    \n",
      "    > max(oldfaith$eruptions)\n",
      "    [1] 5.1"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Putting it all together\n",
      "\n",
      "So why do we care about summary measures of these data? First off, it's usually MUCH faster to obtain summaries of the data than to figure out the best ways to plot that same information.  Finding an intuitive way to make sense of data in a visual way can sometimes be very difficult.  \n",
      "\n",
      "What do these summary measures indicate to us?  By obtaining the median and the mean there can be a rough estimate of whether or not there is skewness in the data.  If the data is unimodal and symmetric, we would see an equal mean and median.  Second we look at the minimum and the maximum to get an idea of the range of the dataset.  We can immediately notice outliers by combining this information with the mean and median.  \n",
      "\n",
      "The idea of summarizing data is to quickly look for anything interesting at this first level of analysis.  \n",
      "\n",
      "### A Quick Aside: An Easier Way to Summarize in R\n",
      "\n",
      "One of the main benefits of R, is that it was built with analyzing data in mind.  In that pursuit there are many functions that make these tasks as easy as one line.  To summarize a dataset in R use the \"summary\" command.  This will summarize both numerical and catagorical data for you.  It's a fast and easy function.\n",
      "\n",
      "    > summary(oldfaith)\n",
      "           id           eruptions        waiting    \n",
      "     Min.   :  1.00   Min.   :1.600   Min.   :43.0  \n",
      "     1st Qu.: 68.75   1st Qu.:2.163   1st Qu.:58.0  \n",
      "     Median :136.50   Median :4.000   Median :76.0  \n",
      "     Mean   :136.50   Mean   :3.488   Mean   :70.9  \n",
      "     3rd Qu.:204.25   3rd Qu.:4.454   3rd Qu.:82.0  \n",
      "     Max.   :272.00   Max.   :5.100   Max.   :96.0  "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Visualizing Numerical Data\n",
      "\n",
      "Let's take a look at different ways of visualizing the Old Faithful Dataset and assess what that tells us about the distributions of the data.\n",
      "\n",
      "There are three primary forms of visualizing data:\n",
      "   \n",
      "   - Boxplots or \"Box and Whisker Plots\"\n",
      "   - Histograms\n",
      "   - Scatter plots"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Boxplots\n",
      "\n",
      "Box plots are the first way to visualize this summary of information that we were just describing. The provide a one dimensional view of our data.  A \"Box and Whisker\" plot attempts to show the inter-quartile range, median, as well as makes a guess at potential outliers."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Boxplots in Python"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "F = plt.figure()\n",
      "\n",
      "plt.subplot(211)\n",
      "plt.boxplot(oldfaith['eruptions'], vert=False)\n",
      "plt.xlabel('Eruption Time in Minutes')\n",
      "\n",
      "plt.subplot(212)\n",
      "plt.boxplot(oldfaith['eruptions'], vert=False)\n",
      "plt.xlabel('Waiting Time in Until Next Eruption')\n",
      "F.set_size_inches(12,8)\n",
      "\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Boxplots in R\n",
      "\n",
      "    boxplot(oldfaith$eruptions, horizontal=TRUE, xlab='Eruption Time in Minutes')\n",
      "    \n",
      "By now you should already be noticing how much less code you'll be writing in R to visualize data..."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Histograms\n",
      "\n",
      "I'm going to completely skip dotplots and go straight into histograms, in my opinion it's hard to find a great use case for dot plots.  Histograms on the other hand are incredibly useful plots.  \n",
      "\n",
      "Histograms are used when trying to assess one variable.  They help visualize the following characteristics of the variable:\n",
      "\n",
      "   - Skewness\n",
      "       - Left Skewed or Right Skewed\n",
      "           - This is determined by the location of the long tail.  When data trail off to the right and subsequently have a longer right tail, the shape is said to be right skewed.\n",
      "           - The opposite is true for left skewed.\n",
      "       - No Skew\n",
      "           - When a histogram has equal length tails and is essentially symmetric, it is said to be symmetric and have no skew.\n",
      "   - Modality \n",
      "       -  This is a description of the number of peaks that a distribution has.  There are essentially three main definitions for the types of modality of a distribution:\n",
      "           - Unimodal - One prominent peak or mode\n",
      "           - Bimodal - Two prominent peaks or modes\n",
      "           - Multimodal - I'm tired of counting peaks\n",
      "\n",
      "**WARNING - A HISTOGRAM IS _NOT_ A BARPLOT!!!!**  Sure they both have bars, but they are completely DIFFERENT beasts."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Plotting Histograms in Python"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "F = plt.figure()\n",
      "plt.subplot(211)\n",
      "plt.hist(oldfaith['eruptions'], bins=np.arange(0, np.max(oldfaith['eruptions']), 0.1))\n",
      "plt.xlabel('Eruption Time in Minutes')\n",
      "plt.ylabel('Frequency')\n",
      "plt.title('Old Faithful Eruption Times')\n",
      "plt.subplot(212)\n",
      "plt.hist(oldfaith['waiting'], bins=np.arange(0, np.max(oldfaith['waiting']), 2))\n",
      "plt.xlabel('Waiting Time Until Next Eruption')\n",
      "plt.ylabel('Frequency')\n",
      "plt.title('Old Faithful Waiting Times')\n",
      "F.set_size_inches(12,10)\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Plotting Histograms in R\n",
      "\n",
      "    hist(oldfaith$eruptions, breaks=seq(0,5.1,0.1), \n",
      "         xlab='Eruption Time in Minutes', \n",
      "         main='Old Faithful Eruption Times')"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Another Data Summary for Numerical Data\n",
      "\n",
      "Another thing that is usually captured when summarizing data is the variability of that variable of the dataset.  If the data is approximately _symmetric and unimodal_, reporting the standard deviation or the variance of the dataset is appropriate and meaningful in the context of Normal distributions.  Otherwise, the standard deviation and variance only tell you a measure of spread of the distribution.  \n",
      "\n",
      "The variance of dataset is roughly the average squared distance from the mean.  While the standard deviation is useful when considering how close the data is to the mean.\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Sample Variance in Python\n",
      "\n",
      "**_Warning_**: This is only a measure of spread for this dataset since the data is bimodal, BUT I wanted to show the actual commands in Python and R for your use."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "eruption_var = np.cov(oldfaith['eruptions'])\n",
      "eruption_sd = np.std(oldfaith['eruptions'])\n",
      "print \"\"\"Estimated Variance of Eruption Time:           {0:.3}\n",
      "Estimated Standard Deviation of Eruption Time: {1:.3}\n",
      "Standard Deviation Squared:                    {2:.3}\"\"\".format(eruption_var, eruption_sd,\n",
      "                                                                eruption_sd**2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Sample Variance in R\n",
      "\n",
      "    > var(oldfaith$eruptions)\n",
      "    [1] 1.302728\n",
      "    \n",
      "    > sd(oldfaith$eruptions)\n",
      "    [1] 1.141371"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Scatter Plots\n",
      "\n",
      "We've left the land of looking at one variable and now consider pairs of variables. A scatter plot is used when you want to compare two numerical variables.  One of the main purposes for a scatter plot is to assess linear trends within a dataset.  Another purpose may be to identify any clustering that may be occuring in the data.  \n",
      "\n",
      "### Scatterplots in Python"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "F = plt.figure()\n",
      "plt.plot(oldfaith['eruptions'], oldfaith['waiting'], \n",
      "         marker='o',linestyle=\"\")\n",
      "plt.xlabel('Eruption Time Minutes')\n",
      "plt.ylabel('Waiting Time Until Next Eruption')\n",
      "F.set_size_inches(8,8)\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Hmm it looks like there might be clustering... Let's try and visualize that."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "F = plt.figure()\n",
      "plt.plot(oldfaith[oldfaith['eruptions'] <= 3.0]['eruptions'], \n",
      "         oldfaith[oldfaith['eruptions'] <= 3.0]['waiting'], \n",
      "         marker='o',linestyle=\"\", color='red')\n",
      "plt.scatter(oldfaith[oldfaith['eruptions'] > 3.0]['eruptions'], \n",
      "         oldfaith[oldfaith['eruptions'] > 3.0]['waiting'], \n",
      "         marker='o', color='blue')\n",
      "plt.xlabel('Eruption Time Minutes')\n",
      "plt.ylabel('Waiting Time Until Next Eruption')\n",
      "F.set_size_inches(8,8)\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Scatterplots in R\n",
      "\n",
      "    plot(oldfaith$eruptions, oldfaith$waiting,\n",
      "         xlab='Eruption Time in Minutes',\n",
      "         ylab='Waiting Time Until Next Eruption',\n",
      "         main='Old Faithful Eruption Times v. Waiting Times')"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Summarizing Categorical Data\n",
      "\n",
      "From the last discussion section, remember that Categorical Data is data that has natural categories.  Let's explore some of the summaries and visualizations here.  The Old Faithful Dataset was useful for numerical data, in this section we'll concern ourselves with the a dataset about Hair and Eye Color.  \n",
      "\n",
      "As a note, visualizing categorical data is sometimes more of an art.  There aren't many packages for creating tables in specific ways and for the most part you're left to make your own tables.  \n",
      "\n",
      "http://stat.ethz.ch/R-manual/R-patched/library/datasets/html/HairEyeColor.html\n",
      "\n",
      "### Loading in this new dataset"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "haireyes = np.genfromtxt('HairEyeColor.csv', delimiter=',', dtype=None, names=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### What does this data look like?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "haireyes[:5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Summarys of Datasets\n",
      "\n",
      "The main ways to visualize categorical data are through frequency/contingency tables and the use of bar plots. \n",
      "\n",
      "The first thing to do when you get a new dataset with categorical variables is to assess what the \"factors\" or \"levels\" are in the data.  These are the unique values for a given variable.  In the case of hair color an example factor could be \"brown\".  Let's take a look at the data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Unique Levels in Python"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "hair_colors = np.unique(haireyes['Hair'])\n",
      "eye_colors = np.unique(haireyes['Eye'])\n",
      "genders = np.unique(haireyes['Sex'])\n",
      "\n",
      "print \"\"\"\n",
      "Unique Hair Colors: {0}\n",
      "Unique Eye Colors:  {1}\n",
      "Unique Genders:     {2}\"\"\".format(hair_colors, eye_colors, genders)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Number of Lines with Each Level"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "counts_hair = []\n",
      "counts_eye = []\n",
      "counts_gender = []\n",
      "print \"Hair Colors:\"\n",
      "for hair in hair_colors:\n",
      "    c = len(haireyes[haireyes['Hair'] == hair])\n",
      "    print \"\\t Num. Lines w/ Hair Color {0}: {1}\".format(hair, c)\n",
      "    counts_hair.append(c)\n",
      "\n",
      "print \"Eye Colors:\"\n",
      "for eye in eye_colors:\n",
      "    c = len(haireyes[haireyes['Eye'] == eye])\n",
      "    print \"\\t Num. Lines w/ Eye Color {0}: {1}\".format(eye, c)\n",
      "    counts_eye.append(c)\n",
      "\n",
      "print \"Genders\"\n",
      "for sex in genders:\n",
      "    c = len(haireyes[haireyes['Sex']== sex])\n",
      "    print \"\\t Num. Lines w/ Gender {0}: {1}\".format(sex, c)\n",
      "    counts_gender.append(c)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Same Summaries in R\n",
      "    > haireyes = read.csv('HairEyeColor.csv')\n",
      "    > summary(haireyes)\n",
      "           X            Hair      Eye        Sex          Freq      \n",
      "     Min.   : 1.00   Black:8   Blue :8   Female:16   Min.   : 2.00  \n",
      "     1st Qu.: 8.75   Blond:8   Brown:8   Male  :16   1st Qu.: 7.00  \n",
      "     Median :16.50   Brown:8   Green:8               Median :10.00  \n",
      "     Mean   :16.50   Red  :8   Hazel:8               Mean   :18.50  \n",
      "     3rd Qu.:24.25                                   3rd Qu.:29.25  \n",
      "     Max.   :32.00                                   Max.   :66.00 "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## What are we missing?\n",
      "\n",
      "Those are great starts to look at your data, but as you can see this datafile has _collapsed_ all of the frequencies in each category.  The counts above are not the numbers that we're actually looking for!  If you look again each line has a total count for the frequency observed with a specific triple of \"Hair, Eye, Sex\".  How should we start to visualize this.  Again we can summarize with sums of counts!\n",
      "\n",
      "First lets define a function to make our lives easier..."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def count_bylevel(level, val):\n",
      "    return np.sum(haireyes[haireyes[level] == val]['Freq'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "freq_hair = []\n",
      "freq_eye = []\n",
      "freq_gender = []\n",
      "\n",
      "print \"Hair Colors:\"\n",
      "for hair in hair_colors:\n",
      "    c = count_bylevel('Hair', hair)\n",
      "    print \"\\t Freq w/ Hair Color {0}: {1}\".format(hair, c)\n",
      "    freq_hair.append(c)\n",
      "\n",
      "print \"Eye Colors:\"\n",
      "for eye in eye_colors:\n",
      "    c = count_bylevel('Eye', eye)\n",
      "    print \"\\t Num. Lines w/ Eye Color {0}: {1}\".format(eye, c)\n",
      "    freq_eye.append(c)\n",
      "\n",
      "print \"Genders\"\n",
      "for sex in genders:\n",
      "    c = count_bylevel('Sex', sex)\n",
      "    print \"\\t Num. Lines w/ Gender {0}: {1}\".format(sex, c)\n",
      "    freq_gender.append(c)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Let's pause and take a look at Visualizing this\n",
      "\n",
      "We've finally obtained some frequencies for given categories.  Now we're equiped to visualize this using a barplot.  \n",
      "\n",
      "### Barplots in Python"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "N = len(hair_colors)\n",
      "ind = np.arange(N)\n",
      "F, ax = plt.subplots()\n",
      "plt.bar(ind,freq_hair)\n",
      "ax.set_xticks(0.4 + ind)\n",
      "ax.set_xticklabels(hair_colors)\n",
      "plt.xlabel('Hair Color')\n",
      "plt.ylabel('Frequency')\n",
      "F.set_size_inches(12,4)\n",
      "plt.show()\n",
      "\n",
      "N = len(eye_colors)\n",
      "ind = np.arange(N)\n",
      "F, ax = plt.subplots()\n",
      "plt.bar(ind,freq_eye)\n",
      "ax.set_xticks(0.4 + ind)\n",
      "ax.set_xticklabels(eye_colors)\n",
      "plt.xlabel('Eye Color')\n",
      "plt.ylabel('Frequency')\n",
      "F.set_size_inches(12,4)\n",
      "plt.show()\n",
      "\n",
      "N = len(genders)\n",
      "ind = np.arange(N)\n",
      "F, ax = plt.subplots()\n",
      "plt.bar(ind,freq_gender)\n",
      "ax.set_xticks(0.4 + ind)\n",
      "ax.set_xticklabels(genders)\n",
      "plt.xlabel('Gender')\n",
      "plt.ylabel('Frequency')\n",
      "F.set_size_inches(12,4)\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Assessing relative frequencies\n",
      "\n",
      "So total frequencies are great, but sometimes they're not the whole picture.  What if we want to visualize the difference between eyecolor between sexes?  Or suppose that we care about the difference between gender and haircolor.  We should break down by those variables"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def counts_gender(level, val):\n",
      "    males = haireyes[haireyes['Sex']=='\"Male\"']\n",
      "    females = haireyes[haireyes['Sex']=='\"Female\"']\n",
      "    m_sum = np.sum(males[males[level]==val]['Freq'])\n",
      "    f_sum = np.sum(females[females[level]==val]['Freq'])\n",
      "    return m_sum, f_sum"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "freq_maleshair = []\n",
      "freq_femaleshair = []\n",
      "freq_maleseye = []\n",
      "freq_femaleseye = []\n",
      "\n",
      "print \"Hair Colors: Males, Females\"\n",
      "for hair in hair_colors:\n",
      "    m, f = counts_gender('Hair', hair)\n",
      "    print \"\\t Freq w/ Hair Color {0}: {1}, {2}\".format(hair, m, f)\n",
      "    freq_maleshair.append(m)\n",
      "    freq_femaleshair.append(f)\n",
      "\n",
      "print \"Eye Colors: Males, Females\"\n",
      "for eye in eye_colors:\n",
      "    m, f = counts_gender('Eye', eye)\n",
      "    print \"\\t Freq w/ Eye Color {0}: {1}, {2}\".format(hair, m, f)\n",
      "    freq_maleseye.append(m)\n",
      "    freq_femaleseye.append(f)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Plotting this visualization in Python"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "N = len(hair_colors)\n",
      "ind = np.arange(N)\n",
      "width = 0.35\n",
      "\n",
      "F, ax = plt.subplots()\n",
      "rects1 = plt.bar(ind, freq_maleshair, width, alpha=0.5)\n",
      "rects2 = plt.bar(ind+width, freq_femaleshair,width, color='red', alpha=0.5)\n",
      "ax.set_xticks(width + ind)\n",
      "ax.set_xticklabels(hair_colors)\n",
      "plt.xlabel('Hair Color')\n",
      "plt.ylabel('Frequency')\n",
      "ax.legend( (rects1[0], rects2[0]), ('Men', 'Women') )\n",
      "F.set_size_inches(12,4)\n",
      "plt.show()\n",
      "\n",
      "F, ax = plt.subplots()\n",
      "rects1 = plt.bar(ind, freq_maleseye, width, alpha=0.5)\n",
      "rects2 = plt.bar(ind+width, freq_femaleseye,width, color='red', alpha=0.5)\n",
      "ax.set_xticks(width + ind)\n",
      "ax.set_xticklabels(hair_colors)\n",
      "plt.xlabel('Eye Color')\n",
      "plt.ylabel('Frequency')\n",
      "ax.legend( (rects1[0], rects2[0]), ('Men', 'Women') )\n",
      "F.set_size_inches(12,4)\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As you can see these can see, the combinations of visualization all of these grouped categories can be daunting when looking at complicated datasets with categorical variables.  When you look at data you should plan what associations seem plausible and segment and plot accordingly\n",
      "\n",
      "### Barplots in R\n",
      "\n",
      "Investigate the following function.  It's complicated for this dataset, but look at others\n",
      "\n",
      "    barplot()"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Now it's time for your sources of inspiration\n",
      "\n",
      "Who does amazing plots and where should you go to see how data is visualized correctly..\n",
      "\n",
      "- Flowing data: http://flowingdata.com/\n",
      "- Reddit's DataIsBeautiful Subreddit: http://www.reddit.com/r/dataisbeautiful\n",
      "- D3 Examples: https://github.com/mbostock/d3/wiki/Gallery\n",
      "- Shiny Examples: http://shiny.rstudio.com/gallery/\n",
      "\n",
      "And also some famous data visualization experts.  They've written books, but don't always assume they're right!\n",
      "\n",
      "- Edward Tufte: http://en.wikipedia.org/wiki/Edward_Tufte\n",
      "- William Cleveland : http://www.stat.purdue.edu/~wsc/\n",
      "\n",
      "Finally some examples of bad visualizations\n",
      "\n",
      "- WTF Visualizations: http://wtfviz.net/"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}